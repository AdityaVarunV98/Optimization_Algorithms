{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YZu2TtwrJNeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3er2ctczDRsl"
      },
      "outputs": [],
      "source": [
        "def newtonMethodMultiDim(objective,\n",
        "                         gradient,\n",
        "                         x0,\n",
        "                         tolerance,\n",
        "                         minima=True,\n",
        "                         max_iterations=10000):\n",
        "    \"\"\"\n",
        "    Implementation of Gradient Descent for unconstrained optimization problems i.e.\n",
        "\n",
        "    min f(x) or max f(x)\n",
        "    s.t. x in R^n and f: R^n -> R\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    objective : function\n",
        "        The objective function for which the maximum/minima needs to be found.\n",
        "    gradient : function\n",
        "        The gradient of the objective function.\n",
        "    x0 : numpy array\n",
        "        The initial guess for the maximum/minima.\n",
        "    tolerance : float\n",
        "        The tolerance for the stopping criteria.\n",
        "    minima : bool\n",
        "        If True, the algorithm will search for the minima, else it will\n",
        "        search for the maxima.\n",
        "    max_iterations : int\n",
        "        The maximum number of iterations for the algorithm if the algorithm\n",
        "        does not converge.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    optima : numpy array\n",
        "        The optimal argument of the objective function.\n",
        "    optimum : float\n",
        "        The optimal value of the objective function.\n",
        "    cache : tuple or None\n",
        "        The cache is returned for the purpose of accessing the values of the\n",
        "        local variables of the algorithm for purposes like plotting or debugging.\n",
        "    \"\"\"\n",
        "\n",
        "    gradient_norms = []\n",
        "    gradients = []\n",
        "    function_vals = []\n",
        "    increments = []\n",
        "    increment_norms = []\n",
        "    x_values = []\n",
        "    trial_points = []\n",
        "\n",
        "    x_values.append(x0)\n",
        "    function_vals.append(objective(x_values[-1]))\n",
        "    gradients.append(gradient(x_values[-1]))\n",
        "    gradient_norms.append(np.linalg.norm(gradients[-1]))\n",
        "    k = 0\n",
        "\n",
        "    while gradient_norms[-1] > tolerance and k < max_iterations:\n",
        "        if(minima):\n",
        "            alpha = 1\n",
        "            beta = 0.5\n",
        "\n",
        "            d_k = -1*gradients[-1]\n",
        "            d_k = np.reshape(d_k, (d_k.shape[0],))\n",
        "\n",
        "            trial_points_k = []\n",
        "            trial_points_k.append(x_values[-1] + alpha*d_k)\n",
        "            while objective(x_values[-1] + alpha*d_k) > function_vals[-1]:\n",
        "                alpha = alpha*beta\n",
        "                trial_points_k.append(x_values[-1] + alpha*d_k)\n",
        "\n",
        "\n",
        "            trial_points.append(trial_points_k)\n",
        "            increments.append(alpha*gradients[-1])\n",
        "            increment_norms.append(np.linalg.norm(increments[-1]))\n",
        "        else:\n",
        "            alpha = 1\n",
        "            beta = 0.5\n",
        "\n",
        "            d_k = -1*gradients[-1]\n",
        "            d_k = np.reshape(d_k, (d_k.shape[0],))\n",
        "\n",
        "            trial_points_k = []\n",
        "            trial_points_k.append(x_values[-1] + alpha*d_k)\n",
        "            while objective(x_values[-1] + alpha*d_k) < objective(x_values[-1]):\n",
        "                alpha = alpha*beta\n",
        "\n",
        "            trial_points.append(trial_points_k)\n",
        "            increments.append(alpha*gradients[-1])\n",
        "            increment_norms.append(np.linalg.norm(increments[-1]))\n",
        "\n",
        "\n",
        "        x_values.append(np.reshape(x_values[-1], (4, 1)) - increments[-1])\n",
        "        x_values[-1] = np.reshape(x_values[-1], (4, ))\n",
        "        function_vals.append(objective(x_values[-1]))\n",
        "        gradients.append(gradient(x_values[-1]))\n",
        "        gradient_norms.append(np.linalg.norm(gradients[-1]))\n",
        "        k = k + 1\n",
        "\n",
        "    for i in range(1, k+1):\n",
        "        print(\"Iteration \" + str(i))\n",
        "        print(\"Trial Points = \")\n",
        "        print(trial_points[i-1])\n",
        "        print(\"Gradient Norm = \")\n",
        "        print(gradient_norms[i])\n",
        "        print(\"Function Value = \")\n",
        "        print(function_vals[i])\n",
        "        print(\" \")\n",
        "\n",
        "    '''\n",
        "    plt.plot(range(k+1), gradient_norms)\n",
        "    plt.grid()\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Norm of Gradient\")\n",
        "    plt.legend([\"Norm of Gradient\"])\n",
        "    plt.title(\"Norm of Gradient vs Iteration\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(range(k+1), function_vals)\n",
        "    plt.grid()\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Function Value\")\n",
        "    plt.legend([\"Function Value\"])\n",
        "    plt.title(\"Function Value vs Iteration\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(range(k), increment_norms)\n",
        "    plt.grid()\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Increment\")\n",
        "    plt.legend([\"Increment\"])\n",
        "    plt.title(\"Increment vs Iteration\")\n",
        "    plt.show()'''\n",
        "\n",
        "    return x_values[-1], function_vals[-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective1(x):\n",
        "    val = 0\n",
        "    for i in range(2):\n",
        "        val += -1*(x[i] - 1)**2 - 100*(x[i+1] - x[i])**2\n",
        "\n",
        "    return val\n",
        "\n",
        "def gradient1(x):\n",
        "    grad = np.array([-2*(x[0] - 1) + 200*(x[1]-x[0]), -200*(x[1]-x[0]) -2*(x[1] - 1) + 200*(x[2]-x[1]), -200*(x[2]-x[1]) -2*(x[2] - 1) + 200*(x[3]-x[2]), -200*(x[3]-x[2])])\n",
        "    grad = np.reshape(grad, (4, 1))\n",
        "    return grad\n",
        "\n",
        "x0 = np.array([1, 0, 0, 0])\n",
        "tolerance = 0.0001\n",
        "\n",
        "minima, minimum_value = newtonMethodMultiDim(objective1, gradient1, x0, tolerance, minima=False, max_iterations=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kYf134hI-eq",
        "outputId": "ea86e37c-f8b7-49a8-b50f-a3b99ce63577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1\n",
            "Trial Points = \n",
            "[array([ 201, -202,   -2,    0])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 2\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  1.73472348e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 3\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  2.16840434e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 4\n",
            "Trial Points = \n",
            "[array([ 2.0100000e+02, -2.0200000e+02, -2.0000000e+00,  2.1955094e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 5\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  2.19720347e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 6\n",
            "Trial Points = \n",
            "[array([ 2.0100000e+02, -2.0200000e+02, -2.0000000e+00,  2.1980505e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 7\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  2.19826226e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 8\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  2.19836814e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 9\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  2.19842108e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n",
            "Iteration 10\n",
            "Trial Points = \n",
            "[array([ 2.01000000e+02, -2.02000000e+02, -2.00000000e+00,  2.19844754e-16])]\n",
            "Gradient Norm = \n",
            "284.26747967363417\n",
            "Function Value = \n",
            "-101.0\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gK60T_Blqcah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}